+ stat_summary(fun.data=bernoulli_mean_ci, geom="pointrange")
+ labs(x="Coherence", y="Proportion correct")
+ geom_hline(y=0.5) + geom_vline(x=0)
+ geom_smooth(method="glm", formula=y~x-1,
family=binomial(link=logit)))
print(psi.plot)
rt.plot <- (
ggplot(fold(rt.data)) + aes(x=rt)
+ stat_density(position="identity", fill="NA", geom="line")
+ labs(x="Response time", y="Density", title="Response time distribution")
+ theme(axis.text.y = element_blank())
+ geom_hline(y=0)
)
print(rt.plot)
slow.error.plot <- (
rt.plot
+ aes(color=factor(response))
+ labs(color="Response\ncorrect"))
print(slow.error.plot)
rt.strength.plot <- (
ggplot(fold(rt.data))
+ aes(rt, color=factor(strength))
+ stat_density(geom="line", position="identity")
+ scale_color_discrete("Strength", h=c(270,0), direction=1)
+ labs(x="Response time", y="Density",
title="Distribution of response times by stimulus strength")
)
print(rt.strength.plot)
(ggplot(fold(rt.data)) + aes(x=factor(strength), y=rt, color=response)
+ stat_summary(fun.data=mean_cl_boot, geom="pointrange",
position=position_dodge(width=0.25))
+ labs(title="RTs conditional on correct answer and stimulus strength",
x="Stimulus strength",
y="Response time",
color="Response\ncorrect"))
m = .9
p = .6
f = 400
s = 1000
p*f + (1-p)*s
p = 0.7
f = 400
s = 600
n = 10000
data <- numeric(n)
data
runif(1, 0, 1)
for(i in 1:n){
num <- runif(1, 0, 1)
if(num < p){
data[i] <- f
} else {
data[i] <- s
}
}
data
mean(data)
?switch
?mean
mean(c(2.13, 2.86, 2.86, 3.37, 2.93, 2.86, 9.96, 2.86, 2.22, 2.99, 2.13, 2.86, 2.93, 3.27, 33.61))
median(c(2.13, 2.86, 2.86, 3.37, 2.93, 2.86, 9.96, 2.86, 2.22, 2.99, 2.13, 2.86, 2.93, 3.27, 33.61))
sd(c(2.13, 2.86, 2.86, 3.37, 2.93, 2.86, 9.96, 2.86, 2.22, 2.99, 2.13, 2.86, 2.93, 3.27, 33.61))
324/6
9/6
9/5
23/6
library(shiny)
runGitHub("shiny_example", "rstudio")
runGitHub("shiny_example", "rstudio")
runGitHub("shiny_example", "rstudio", subdir = "inst/shinyapp/")
runGitHub("shiny_example", "rstudio", subdir = "inst/shinyapp/")
shiny::runGitHub("shiny-examples", "rstudio", subdir = "001-hello")
shiny::runGitHub("shiny-examples", "rstudio", subdir = "082-word-cloud")
shiny::runGitHub("shiny-examples", "rstudio", subdir = "004-mpg")
x <- seq(0, 1, length.out = 10000)
plot(x, dnorm(x, mean = 0.5, sd = 0.1))
plot(x, pnorm(x, mean = 0.5, sd = 0.1))
integrate(dnorm, lower = 0, upper = 0.6, mean = 0.5, sd = 0.1)
x <- seq(0, 1, length.out = 10000)
par(mfrow = c(1, 2))
plot(x, dnorm(x, mean = 0.5, sd = 0.1))
plot(x, pnorm(x, mean = 0.5, sd = 0.1))
integrate(dnorm, lower = 0, upper = 0.6, mean = 0.5, sd = 0.1)
x <- seq(0, 1, length.out = 10000)
par(mfrow = c(1, 2))
plot(x, dnorm(x, mean = 0.5, sd = 0.1))
plot(x, pnorm(x, mean = 0.5, sd = 0.1))
abline(v = 0.6)
integrate(dnorm, lower = 0, upper = 0.6, mean = 0.5, sd = 0.1)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
z
y
which(y == .6)
which(y == 0.6)[[1]]
match(0.6, y)
which(0.6 == y)[[1]]
which(>0.6 == y)[[1]]
which(0.6 > y)[[1]]
y[1]
which(0.6 < y)[[1]]
y[5254]
z[5254]
y[5254]
y
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.8 < y)[[1]]
par(mfrow = c(1, 2))
plot(x, z)
plot(x, y)
abline(h = 0.8, v = a)
a
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.8 < y)[[1]]
par(mfrow = c(1, 2))
plot(x, z)
plot(x, y)
abline(h = 0.8, v = x[a])
integrate(dnorm, lower = 0, upper = x[a], mean = 0.5, sd = 0.1)
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.8 < y)[[1]]
# plot the PDF (left) and CDF (right)
par(mfrow = c(1, 2))
plot(x, z, type = "l", ylab = PDF(x))
plot(x, y, type = "l", ylab = CDF(x))
abline(h = 0.8, v = x[a])
integrate(dnorm, lower = 0, upper = x[a], mean = 0.5, sd = 0.1)
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.8 < y)[[1]]
# plot the PDF (left) and CDF (right)
par(mfrow = c(1, 2))
plot(x, z, type = "l", ylab = "PDF(x)")
plot(x, y, type = "l", ylab = "CDF(x)")
abline(h = 0.8, v = x[a])
integrate(dnorm, lower = 0, upper = x[a], mean = 0.5, sd = 0.1)
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.8 < y)[[1]]
# plot the PDF (left) and CDF (right)
par(mfrow = c(1, 2))
plot(x, z, type = "l", ylab = "PDF(x)")
plot(x, y, type = "l", ylab = "CDF(x)")
abline(h = 0.8, v = x[a], col = "red")
integrate(dnorm, lower = 0, upper = x[a], mean = 0.5, sd = 0.1)
which(0.6 < x)[[1]]
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.6 < x)[[1]]
# plot the PDF (left) and CDF (right)
par(mfrow = c(1, 2))
plot(x, z, type = "l", ylab = "PDF(x)")
plot(x, y, type = "l", ylab = "CDF(x)")
abline(h = y[a], v = x[a], col = "red")
integrate(dnorm, lower = 0, upper = x[a], mean = 0.5, sd = 0.1)
y[a]
log(0.01)
log(0.1)
log(1)
log(1.1)
log(1.001)
5 add 4
![This](C:\Users\Home\Desktop\bf.png)
library(BayesFactor)
?ttestBF
sqrt(2)
BFrobustplot <- function(ts, ns, rs=seq(0, 2, length.out=200), labels=c(), dots=1, plot=TRUE, sides="two", nrow=2, xticks=3) {
library(BayesFactor)
# compute one-sided p-values from ts and ns
ps <- pt(ts, df=ns-1, lower.tail = FALSE)   # one-sided test
# add the dots location to the sequences of r's
rs <- c(rs, dots)
res <- data.frame()
for (r in rs) {
# first: calculate two-sided BF
B_e0 <- c()
for (i in 1:length(ts))
B_e0 <- c(B_e0, exp(ttest.tstat(t = ts[i], n1 = ns[i], rscale=r)$bf))
# second: calculate one-sided BF
B_r0 <- c()
for (i in 1:length(ts)) {
if (ts[i] > 0) {
# correct direction
B_r0 <- c(B_r0, (2 - 2*ps[i])*B_e0[i])
} else {
# wrong direction
B_r0 <- c(B_r0, (1 - ps[i])*2*B_e0[i])
}
}
res0 <- data.frame(t=ts, n=ns, BF_two=B_e0, BF_one=B_r0, r=r)
if (length(labels) > 0) {
res0$labels <- labels
res0$heading <- factor(1:length(labels), labels=paste0(labels, "\n(t = ", ts, ", df = ", ns-1, ")"), ordered=TRUE)
} else {
res0$heading <- factor(1:length(ts), labels=paste0("t = ", ts, ", df = ", ns-1), ordered=TRUE)
}
res <- rbind(res, res0)
}
# define the measure to be plotted: one- or two-sided?
# log-transform and reverse the sign in order to get the direction of BF as plotted in Wagenmakers, E., Wetzels, R., & Borsboom, D. (n.d.). Yes, Psychologists Must Change the Way They Analyze Their Data: Clarifications for Bem, Utts, and Johnson (2011). Journal of Personality.
res$BF <- 1/res[, paste0("BF_", sides)]
if (plot==TRUE) {
library(ggplot2)
p1 <- ggplot(res, aes(x=r, y=log(BF))) + geom_line() + facet_wrap(~heading, nrow=nrow) + theme_bw() + ylab("log(BF)")
p1 <- p1 + geom_hline(yintercept=c(c(-log(c(30, 10, 3)), log(c(3, 10, 30)))), linetype="dotted", color="darkgrey")
p1 <- p1 + geom_hline(yintercept=log(1), linetype="dashed", color="darkgreen")
# add the dots
p1 <- p1 + geom_point(data=res[res$r %in% dots,], aes(x=r, y=log(BF)), color="red", size=2)
# add annotation
p1 <- p1 + annotate("text", x=max(rs)*1.8, y=-2.85, label="Strong~H[1]", hjust=1, vjust=.5, size=3, color="black", parse=TRUE)
p1 <- p1 + annotate("text", x=max(rs)*1.8, y=-1.7 , label="Moderate~H[1]", hjust=1, vjust=.5, size=3, color="black", parse=TRUE)
p1 <- p1 + annotate("text", x=max(rs)*1.8, y=-.55 , label="Anectodal~H[1]", hjust=1, vjust=.5, size=3, color="black", parse=TRUE)
p1 <- p1 + annotate("text", x=max(rs)*1.8, y=2.86 , label="Strong~H[0]", hjust=1, vjust=.5, size=3, color="black", parse=TRUE)
p1 <- p1 + annotate("text", x=max(rs)*1.8, y=1.7  , label="Moderate~H[0]", hjust=1, vjust=.5, size=3, color="black", parse=TRUE)
p1 <- p1 + annotate("text", x=max(rs)*1.8, y=.55  , label="Anectodal~H[0]", hjust=1, vjust=.5, vjust=.5, size=3, color="black", parse=TRUE)
# set scale ticks
p1 <- p1 + scale_y_continuous(breaks=c(c(-log(c(30, 10, 3)), 0, log(c(3, 10, 30)))), labels=c("-log(30)", "-log(10)", "-log(3)", "log(1)", "log(3)", "log(10)", "log(30)"))
p1 <- p1 + scale_x_continuous(breaks=seq(min(rs), max(rs), length.out=xticks))
return(p1)
} else {
return(res)
}
}
BFrobustplot(ts = 3.098, ns = 76)
# clear workspace
rm(list = ls())
# set working directory
setwd("~/Git/paperData/2015/Episodic Retrieval & Inhibition/Data & Analysis Code")
# load necessary functions file & load necessary packages
source("functions.R")
library(dplyr)
library(ggplot2)
library(ez)
library(BayesFactor)
library(BEST)
# load the data file
fullData <- read.csv("allData.csv", header = TRUE)
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
### Error Data Trimming
# Remove null trials (1st and 2nd trial of each block)
# which trials were null?
nullTrials <- c(1, 2, 121, 122, 241, 242, 361, 362)
# remove these trials
data <- fullData[! fullData$trial %in% nullTrials, ]
# add column to code for removing two trials following an error, initialised
# to zero
data <- mutate(data, accTrim = 0)
# populate this column
for(i in 3:nrow(data)){
data$accTrim[i] <- data$accuracy[i - 2] * data$accuracy[i - 1]
}
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
### Error Analysis
# First, we need to see the OVERALL accuracy per participant, as we will want
# to remove people who do not meet a certain criteria
accuracy <- data %>%
group_by(subject) %>%
summarise(meanAccuracy = (sum(accuracy) / length(accuracy) * 100))
# which subjects fall below our criterion of 90% accuracy?
errorRemove <- accuracy[accuracy$meanAccuracy <= 90, ]$subject
# remove these subjects from the data file
data <- data[! data$subject %in% errorRemove, ]
# remove the 2 trials following an error
data <- subset(data, data$accTrim == 1)
# now produce a data frame with accuracy analysis per condition
accuracy <- data %>%
group_by(subject, stimRep, sequence) %>%
summarise(acc = (sum(accuracy) / length(accuracy)))
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
### response time analysis
# remove all error trials, so we are ready for RT analysis
data <- subset(data, data$accuracy == 1)
# trim the RTs with fixed standard deviation upper limit
rtData <- getRTs(data = data, minRT = 150, sd = 2.5)
#---------
# calculate the mean BI for each condition
biRT <- rtData %>%
group_by(subject) %>%
summarise(rep = abaRep - cbaRep, sw = abaSw - cbaSw)
# get the difference score
biDiff <- biRT$rep - biRT$sw
#---------
# Bayes Factor Analysis
# what is the Bayes Factor of the difference in BI between stimRep & stimSw?
bfDiff <- ttestBF(x = biDiff, rscale = 0.707)
# plot the progression of the Bayes Factor of the interaction as more
# subjects are added
bfProg <- plotBF(biDiff, scale = 0.707)
bfProg[, 2] <- log(bfProg[, 2])
bfProg[1, 2] <- 0
pdf("bayesFactor.pdf", width = 8, height = 5)
plot(bfProg[, 1], bfProg[, 2], type = "b", xlab = "Sample Size",
ylab = "(Log) Bayes Factor (10)", ylim = c(-2.5, 2.5), pch = 19,
col = "gray48", lwd = 2)
abline(h = 0, lwd = 1)
abline(h = log(6), col = "black", lty = 2, lwd = 2)
abline(h = log(1/6), col = "black", lty = 2, lwd = 2)
text(0, log(3) + 0.4, labels = "Evidence for Alternative",
cex = 1.5, col = "black", pos = 4)
text(0, log(1/3) - 0.4, labels = "Evidence for Null",
cex = 1.5, col = "black", pos = 4)
dev.off()
#---
## robustness check based on prior
# what is the t-value for the data?
tVal <- as.numeric(t.test(biRT$rep, biRT$sw, paired = TRUE)[['statistic']])
# what are the priors to explore?
priors <- seq(from = 0.01, to = 1.5, length.out = 1000)
# get the Bayes factor for each prior value
robust <- sapply(priors, function(x)
exp(ttest.tstat(t = tVal, n1 = nrow(biRT), rscale = x)[['bf']]))
# plot it
pdf("robustPrior.pdf", width = 8, height = 5)
plot(priors, robust, type = "l", lwd = 2, col = "gray48",
ylim = c(0, max(robust)), xaxt = "n", xlab = "Caucy Prior Width",
ylab = "Bayes Factor (10)")
abline(h = 0, lwd = 1)
abline(h = 6, col = "black", lty = 2, lwd = 2)
axis(1, at = seq(0, 1.5, 0.25))
points(0.707, extractBF(bfDiff, onlybf = TRUE), col = "black",
cex = 2, pch = 21, bg = "black")
legend(x = 1, y = 13, legend = c("User Prior", "Stopping Rule"),
pch = c(21, NA), lty = c(NA, 2), lwd = c(NA, 2), pt.cex = c(2, NA),
col = c("black", "black"), pt.bg = "black", bty = "n")
dev.off()
pdf("robustPrior.pdf", width = 8, height = 5)
plot(priors, robust, type = "l", lwd = 2, col = "gray48",
ylim = c(0, max(robust)), xaxt = "n", xlab = "Caucy Prior Width (r)",
ylab = "Bayes Factor (10)")
abline(h = 0, lwd = 1)
abline(h = 6, col = "black", lty = 2, lwd = 2)
axis(1, at = seq(0, 1.5, 0.25))
points(0.707, extractBF(bfDiff, onlybf = TRUE), col = "black",
cex = 2, pch = 21, bg = "black")
legend(x = 1, y = 13, legend = c("User Prior", "Stopping Rule"),
pch = c(21, NA), lty = c(NA, 2), lwd = c(NA, 2), pt.cex = c(2, NA),
col = c("black", "black"), pt.bg = "black", bty = "n")
dev.off()
pdf("robustPrior.pdf", width = 8, height = 5)
plot(priors, robust, type = "l", lwd = 2, col = "gray48",
ylim = c(0, max(robust)), xaxt = "n", xlab = "Caucy Prior Width (r)",
ylab = "Bayes Factor (10)")
abline(h = 0, lwd = 1)
abline(h = 6, col = "black", lty = 2, lwd = 2)
axis(1, at = seq(0, 1.5, 0.25))
points(0.707, extractBF(bfDiff, onlybf = TRUE), col = "black",
cex = 1.5, pch = 21, bg = "black")
legend(x = 1, y = 13, legend = c("User Prior", "Stopping Rule"),
pch = c(21, NA), lty = c(NA, 2), lwd = c(NA, 2), pt.cex = c(1.5, NA),
col = c("black", "black"), pt.bg = "black", bty = "n")
dev.off()
pdf("robustPrior.pdf", width = 8, height = 5)
plot(priors, robust, type = "l", lwd = 2, col = "gray48",
ylim = c(0, max(robust)), xaxt = "n", xlab = "Caucy Prior Width (r)",
ylab = "Bayes Factor (10)")
abline(h = 0, lwd = 1)
abline(h = 6, col = "black", lty = 2, lwd = 2)
axis(1, at = seq(0, 1.5, 0.25))
points(0.707, extractBF(bfDiff, onlybf = TRUE), col = "black",
cex = 1, pch = 21, bg = "black")
legend(x = 1, y = 13, legend = c("User Prior", "Stopping Rule"),
pch = c(21, NA), lty = c(NA, 2), lwd = c(NA, 2), pt.cex = c(1, NA),
col = c("black", "black"), pt.bg = "black", bty = "n")
dev.off()
pdf("robustPrior.pdf", width = 8, height = 5)
plot(priors, robust, type = "l", lwd = 2, col = "gray48",
ylim = c(0, max(robust)), xaxt = "n", xlab = "Caucy Prior Width (r)",
ylab = "Bayes Factor (10)")
abline(h = 0, lwd = 1)
abline(h = 6, col = "black", lty = 2, lwd = 2)
axis(1, at = seq(0, 1.5, 0.25))
points(0.707, extractBF(bfDiff, onlybf = TRUE), col = "black",
cex = 1, pch = 21, bg = "black")
legend(x = 1, y = 13, legend = c("Default Prior", "Stopping Rule"),
pch = c(21, NA), lty = c(NA, 2), lwd = c(NA, 2), pt.cex = c(1, NA),
col = c("black", "black"), pt.bg = "black", bty = "n")
dev.off()
# clear workspace
rm(list = ls())
# set working directory
setwd("~/Git/paperData/2015/Episodic Retrieval & Inhibition/Data & Analysis Code")
# load necessary functions file & load necessary packages
source("functions.R")
library(dplyr)
library(ggplot2)
library(ez)
library(BayesFactor)
library(BEST)
# load the data file
fullData <- read.csv("allData.csv", header = TRUE)
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
### Error Data Trimming
# Remove null trials (1st and 2nd trial of each block)
# which trials were null?
nullTrials <- c(1, 2, 121, 122, 241, 242, 361, 362)
# remove these trials
data <- fullData[! fullData$trial %in% nullTrials, ]
# add column to code for removing two trials following an error, initialised
# to zero
data <- mutate(data, accTrim = 0)
# populate this column
for(i in 3:nrow(data)){
data$accTrim[i] <- data$accuracy[i - 2] * data$accuracy[i - 1]
}
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
### Error Analysis
# First, we need to see the OVERALL accuracy per participant, as we will want
# to remove people who do not meet a certain criteria
accuracy <- data %>%
group_by(subject) %>%
summarise(meanAccuracy = (sum(accuracy) / length(accuracy) * 100))
# which subjects fall below our criterion of 90% accuracy?
errorRemove <- accuracy[accuracy$meanAccuracy <= 90, ]$subject
# remove these subjects from the data file
data <- data[! data$subject %in% errorRemove, ]
# remove the 2 trials following an error
data <- subset(data, data$accTrim == 1)
# now produce a data frame with accuracy analysis per condition
accuracy <- data %>%
group_by(subject, stimRep, sequence) %>%
summarise(acc = (sum(accuracy) / length(accuracy)))
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
### response time analysis
# remove all error trials, so we are ready for RT analysis
data <- subset(data, data$accuracy == 1)
# trim the RTs with fixed standard deviation upper limit
rtData <- getRTs(data = data, minRT = 150, sd = 2.5)
#---------
# calculate the mean BI for each condition
biRT <- rtData %>%
group_by(subject) %>%
summarise(rep = abaRep - cbaRep, sw = abaSw - cbaSw)
# get the difference score
biDiff <- biRT$rep - biRT$sw
# what is the t-value for the data?
tVal <- as.numeric(t.test(biRT$rep, biRT$sw, paired = TRUE)[['statistic']])
# what are the priors to explore?
priors <- seq(from = 0.01, to = 1.5, length.out = 1000)
# get the Bayes factor for each prior value
robust <- sapply(priors, function(x)
exp(ttest.tstat(t = tVal, n1 = nrow(biRT), rscale = x)[['bf']]))
# plot it
pdf("robustPrior.pdf", width = 8, height = 5)
plot(priors, robust, type = "l", lwd = 2, col = "gray48",
ylim = c(0, max(robust)), xaxt = "n", xlab = "Cauchy Prior Width (r)",
ylab = "Bayes Factor (10)")
abline(h = 0, lwd = 1)
abline(h = 6, col = "black", lty = 2, lwd = 2)
axis(1, at = seq(0, 1.5, 0.25))
points(0.707, extractBF(bfDiff, onlybf = TRUE), col = "black",
cex = 1, pch = 21, bg = "black")
legend(x = 1, y = 13, legend = c("Default Prior", "Stopping Rule"),
pch = c(21, NA), lty = c(NA, 2), lwd = c(NA, 2), pt.cex = c(1, NA),
col = c("black", "black"), pt.bg = "black", bty = "n")
dev.off()
what is the Bayes Factor of the difference in BI between stimRep & stimSw?
bfDiff <- ttestBF(x = biDiff, rscale = 0.707)
# plot the progression of the Bayes Factor of the interaction as more
# subjects are added
bfProg <- plotBF(biDiff, scale = 0.707)
bfProg[, 2] <- log(bfProg[, 2])
bfProg[1, 2] <- 0
pdf("bayesFactor.pdf", width = 8, height = 5)
plot(bfProg[, 1], bfProg[, 2], type = "b", xlab = "Sample Size",
ylab = "(Log) Bayes Factor (10)", ylim = c(-2.5, 2.5), pch = 19,
col = "gray48", lwd = 2)
abline(h = 0, lwd = 1)
abline(h = log(6), col = "black", lty = 2, lwd = 2)
abline(h = log(1/6), col = "black", lty = 2, lwd = 2)
text(0, log(3) + 0.4, labels = "Evidence for Alternative",
cex = 1.5, col = "black", pos = 4)
text(0, log(1/3) - 0.4, labels = "Evidence for Null",
cex = 1.5, col = "black", pos = 4)
dev.off()
#---
## robustness check based on prior
# what is the t-value for the data?
tVal <- as.numeric(t.test(biRT$rep, biRT$sw, paired = TRUE)[['statistic']])
# what are the priors to explore?
priors <- seq(from = 0.01, to = 1.5, length.out = 1000)
# get the Bayes factor for each prior value
robust <- sapply(priors, function(x)
exp(ttest.tstat(t = tVal, n1 = nrow(biRT), rscale = x)[['bf']]))
# plot it
pdf("robustPrior.pdf", width = 8, height = 5)
plot(priors, robust, type = "l", lwd = 2, col = "gray48",
ylim = c(0, max(robust)), xaxt = "n", xlab = "Cauchy Prior Width (r)",
ylab = "Bayes Factor (10)")
abline(h = 0, lwd = 1)
abline(h = 6, col = "black", lty = 2, lwd = 2)
axis(1, at = seq(0, 1.5, 0.25))
points(0.707, extractBF(bfDiff, onlybf = TRUE), col = "black",
cex = 1, pch = 21, bg = "black")
legend(x = 1, y = 13, legend = c("Default Prior", "Stopping Rule"),
pch = c(21, NA), lty = c(NA, 2), lwd = c(NA, 2), pt.cex = c(1, NA),
col = c("black", "black"), pt.bg = "black", bty = "n")
dev.off()
