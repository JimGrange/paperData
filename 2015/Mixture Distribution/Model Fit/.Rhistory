data(exampleData)
fit <- fitDSTP(data = exampleData, conditionName = "present", nTrials = 200)
plotFitDSTP(fit, exampleData, conditionName = "present")
?cumsum
cumsum(1:2)
cumsum(1:5)
sim_single_trial <- function
(
strength=0,           #strength of signal
bias=0,               #constant added to drift (parameter)
startingpoint=0,      #another bias parameter
noise=1,              #how much variance accumulates per unit time (>0)
bound=1,              #how high the bounds on the accumulator (>0)
timestep=0.02,        #how small the timestep
ndt = 0.2,            #residual decision/reaction time (>0)
fuzz = 0.05,          #response time fuzz (to hide timesteps) (>0)
nsteps=250)
{
decision_variable <- cumsum(rnorm(n=nsteps,
mean=(bias + strength)*timestep,
sd=sqrt(noise) * sqrt(timestep))) + startingpoint
escape_step <- which(abs(decision_variable) > bound)[1]
c(rt=ndt + escape_step * timestep + rnorm(1, sd=fuzz),
response = decision_variable[escape_step] > 0)
}
sim <- function
(
strength=0,           #strength of signal
bias=0,               #constant added to drift (parameter)
startingpoint=0,      #another bias parameter
noise=1,              #how much variance accumulates per unit time (>0)
bound=1,              #how high the bounds on the accumulator (>0)
timestep=0.02,        #how small the timestep
ndt = 0.2,            #residual decision/reaction time (>0)
fuzz = 0.05,          #response time fuzz (to hide timesteps) (>0)
nsteps=250)
{
decision_variable <- cumsum(rnorm(n=nsteps,
mean=(bias + strength)*timestep,
sd=sqrt(noise) * sqrt(timestep))) + startingpoint
escape_step <- which(abs(decision_variable) > bound)[1]
c(rt=ndt + escape_step * timestep + rnorm(1, sd=fuzz),
response = decision_variable[escape_step] > 0)
}
sim()
sim(strength = 0.3)
sim(strength = 0.3)
sim(strength = 0.3)
sim(strength = 0.3)
sim(strength = 0.3)
sim(strength = 0.3)
sim(strength = 0.3)
sim(strength = 0.3)
sim(strength = 0.3)
strength=0,           #strength of signal
bias=0,               #constant added to drift (parameter)
startingpoint=0,      #another bias parameter
noise=1,              #how much variance accumulates per unit time (>0)
bound=1,              #how high the bounds on the accumulator (>0)
timestep=0.02,        #how small the timestep
ndt = 0.2,            #residual decision/reaction time (>0)
fuzz = 0.05,          #response time fuzz (to hide timesteps) (>0)
nsteps=250)
strength=0
bias=0
startingpoint=0
noise=1
bound=1
timestep=0.02
ndt = 0.2
fuzz = 0.05
nsteps=250
decision_variable <- cumsum(rnorm(n=nsteps,
mean=(bias + strength)*timestep,
sd=sqrt(noise) * sqrt(timestep))) + startingpoint
decision_variable
plot(decision_variable)
plot(decision_variable, type = "l")
which(abs(decision_variable) > bound)[1]
escape_step <- which(abs(decision_variable) > bound)[1]
decision_variable[104]
decision_variable[103]
decision_variable[105]
escape_step * timestep
rnorm(1, sd=fuzz)
rt=ndt + escape_step * timestep + rnorm(1, sd=fuzz)
rt
decision_variable[escape_step] > 0
response = decision_variable[escape_step] > 0
response
c(rt=ndt + escape_step * timestep + rnorm(1, sd=fuzz),
response = decision_variable[escape_step] > 0)
strengths <- as.vector((2^(10:15) / 10000) %o% c(-1, 1))
strengths
rt.data <- rdply(1000, cbind(strength=strengths, ldply(strengths, sim_single_trial)))
library(plyr)
rt.data <- rdply(1000, cbind(strength=strengths, ldply(strengths, sim_single_trial)))
rt.data
head(rt.data)
library(ggplot2)
library(plyr)
theme_set(theme_bw())
theme_update(panel.border=element_blank())
# This function simulates a single reaction time trial, producing a named vector
# of the reaction time and the binary response.
sim_single_trial <- function
(
strength=0,           #strength of signal
bias=0,               #constant added to drift (parameter)
startingpoint=0,      #another bias parameter
noise=1,              #how much variance accumulates per unit time (>0)
bound=1,              #how high the bounds on the accumulator (>0)
timestep=0.02,        #how small the timestep
ndt = 0.2,            #residual decision/reaction time (>0)
fuzz = 0.05,          #response time fuzz (to hide timesteps) (>0)
nsteps=250)
{
decision_variable <- cumsum(rnorm(n=nsteps,
mean=(bias + strength)*timestep,
sd=sqrt(noise) * sqrt(timestep))) + startingpoint
escape_step <- which(abs(decision_variable) > bound)[1]
c(rt=ndt + escape_step * timestep + rnorm(1, sd=fuzz),
response = decision_variable[escape_step] > 0)
}
sim_single_trial(strength=0.3)
#"strength" is the strength of the signal in the stimulus; a typical
#experiment will use a mixture of strengths, positive and negative,
#Here are the strengths we will use:
strengths <- as.vector((2^(10:15) / 10000) %o% c(-1, 1))
strengths
#Simulate 1000 trials at each strength.
rt.data <- rdply(1000, cbind(strength=strengths, ldply(strengths, sim_single_trial)))
rt.data$.n <- NULL
head(rt.data)
rt.data <- subset(rt.data, !(is.na(rt) | rt > 4))
rt,data()
rt.data[sample(nrow(rt.data), 10),]
fold <- function(data)
mutate(data,
response = xor(response, strength<0),
strength = abs(strength))
bernoulli_mean_ci <- function(x) {
conf = prop.test(sum(as.logical(x)), length(x))$conf.int
data.frame(y = mean(x), ymin = conf[1], ymax = conf[2])
}
psi.plot <- (
ggplot(fold(rt.data))
+ aes(x=strength, y=as.numeric(response))
+ stat_summary(fun.data=bernoulli_mean_ci, geom="pointrange")
+ labs(x="Coherence", y="Proportion correct")
+ geom_hline(y=0.5) + geom_vline(x=0)
+ geom_smooth(method="glm", formula=y~x-1,
family=binomial(link=logit)))
print(psi.plot)
rt.plot <- (
ggplot(fold(rt.data)) + aes(x=rt)
+ stat_density(position="identity", fill="NA", geom="line")
+ labs(x="Response time", y="Density", title="Response time distribution")
+ theme(axis.text.y = element_blank())
+ geom_hline(y=0)
)
print(rt.plot)
slow.error.plot <- (
rt.plot
+ aes(color=factor(response))
+ labs(color="Response\ncorrect"))
print(slow.error.plot)
rt.strength.plot <- (
ggplot(fold(rt.data))
+ aes(rt, color=factor(strength))
+ stat_density(geom="line", position="identity")
+ scale_color_discrete("Strength", h=c(270,0), direction=1)
+ labs(x="Response time", y="Density",
title="Distribution of response times by stimulus strength")
)
print(rt.strength.plot)
(ggplot(fold(rt.data)) + aes(x=factor(strength), y=rt, color=response)
+ stat_summary(fun.data=mean_cl_boot, geom="pointrange",
position=position_dodge(width=0.25))
+ labs(title="RTs conditional on correct answer and stimulus strength",
x="Stimulus strength",
y="Response time",
color="Response\ncorrect"))
m = .9
p = .6
f = 400
s = 1000
p*f + (1-p)*s
p = 0.7
f = 400
s = 600
n = 10000
data <- numeric(n)
data
runif(1, 0, 1)
for(i in 1:n){
num <- runif(1, 0, 1)
if(num < p){
data[i] <- f
} else {
data[i] <- s
}
}
data
mean(data)
?switch
?mean
mean(c(2.13, 2.86, 2.86, 3.37, 2.93, 2.86, 9.96, 2.86, 2.22, 2.99, 2.13, 2.86, 2.93, 3.27, 33.61))
median(c(2.13, 2.86, 2.86, 3.37, 2.93, 2.86, 9.96, 2.86, 2.22, 2.99, 2.13, 2.86, 2.93, 3.27, 33.61))
sd(c(2.13, 2.86, 2.86, 3.37, 2.93, 2.86, 9.96, 2.86, 2.22, 2.99, 2.13, 2.86, 2.93, 3.27, 33.61))
324/6
9/6
9/5
23/6
library(shiny)
runGitHub("shiny_example", "rstudio")
runGitHub("shiny_example", "rstudio")
runGitHub("shiny_example", "rstudio", subdir = "inst/shinyapp/")
runGitHub("shiny_example", "rstudio", subdir = "inst/shinyapp/")
shiny::runGitHub("shiny-examples", "rstudio", subdir = "001-hello")
shiny::runGitHub("shiny-examples", "rstudio", subdir = "082-word-cloud")
shiny::runGitHub("shiny-examples", "rstudio", subdir = "004-mpg")
x <- seq(0, 1, length.out = 10000)
plot(x, dnorm(x, mean = 0.5, sd = 0.1))
plot(x, pnorm(x, mean = 0.5, sd = 0.1))
integrate(dnorm, lower = 0, upper = 0.6, mean = 0.5, sd = 0.1)
x <- seq(0, 1, length.out = 10000)
par(mfrow = c(1, 2))
plot(x, dnorm(x, mean = 0.5, sd = 0.1))
plot(x, pnorm(x, mean = 0.5, sd = 0.1))
integrate(dnorm, lower = 0, upper = 0.6, mean = 0.5, sd = 0.1)
x <- seq(0, 1, length.out = 10000)
par(mfrow = c(1, 2))
plot(x, dnorm(x, mean = 0.5, sd = 0.1))
plot(x, pnorm(x, mean = 0.5, sd = 0.1))
abline(v = 0.6)
integrate(dnorm, lower = 0, upper = 0.6, mean = 0.5, sd = 0.1)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
z
y
which(y == .6)
which(y == 0.6)[[1]]
match(0.6, y)
which(0.6 == y)[[1]]
which(>0.6 == y)[[1]]
which(0.6 > y)[[1]]
y[1]
which(0.6 < y)[[1]]
y[5254]
z[5254]
y[5254]
y
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.8 < y)[[1]]
par(mfrow = c(1, 2))
plot(x, z)
plot(x, y)
abline(h = 0.8, v = a)
a
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.8 < y)[[1]]
par(mfrow = c(1, 2))
plot(x, z)
plot(x, y)
abline(h = 0.8, v = x[a])
integrate(dnorm, lower = 0, upper = x[a], mean = 0.5, sd = 0.1)
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.8 < y)[[1]]
# plot the PDF (left) and CDF (right)
par(mfrow = c(1, 2))
plot(x, z, type = "l", ylab = PDF(x))
plot(x, y, type = "l", ylab = CDF(x))
abline(h = 0.8, v = x[a])
integrate(dnorm, lower = 0, upper = x[a], mean = 0.5, sd = 0.1)
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.8 < y)[[1]]
# plot the PDF (left) and CDF (right)
par(mfrow = c(1, 2))
plot(x, z, type = "l", ylab = "PDF(x)")
plot(x, y, type = "l", ylab = "CDF(x)")
abline(h = 0.8, v = x[a])
integrate(dnorm, lower = 0, upper = x[a], mean = 0.5, sd = 0.1)
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.8 < y)[[1]]
# plot the PDF (left) and CDF (right)
par(mfrow = c(1, 2))
plot(x, z, type = "l", ylab = "PDF(x)")
plot(x, y, type = "l", ylab = "CDF(x)")
abline(h = 0.8, v = x[a], col = "red")
integrate(dnorm, lower = 0, upper = x[a], mean = 0.5, sd = 0.1)
which(0.6 < x)[[1]]
x <- seq(0, 1, length.out = 10000)
z <- dnorm(x, mean = 0.5, sd = 0.1)
y <- pnorm(x, mea = 0.5, sd = 0.1)
a <- which(0.6 < x)[[1]]
# plot the PDF (left) and CDF (right)
par(mfrow = c(1, 2))
plot(x, z, type = "l", ylab = "PDF(x)")
plot(x, y, type = "l", ylab = "CDF(x)")
abline(h = y[a], v = x[a], col = "red")
integrate(dnorm, lower = 0, upper = x[a], mean = 0.5, sd = 0.1)
y[a]
log(0.01)
log(0.1)
log(1)
log(1.1)
log(1.001)
5 add 4
setwd("~/Git/paperData/2015/Mixture Distribution/Model Fit")
#------------------------------------------------------------------------------
rm(list = ls())
setwd("~/Git/paperData/2015/Mixture Distribution/Model Fit")
# load required libraries & functions
library(dplyr)
source("functions.R")
# get the data (& do trimming & round RTs to nearest integer)
data <- read.csv("data.csv")
data <- subset(data, data$condition == "Memory" & data$errorTrimming == 1 &
data$sequence != "null" & data$sequence == "repeat")
# change the "subject" to participant, just for the SD trimming
colnames(data)[1] <- "participant"
# do the SD trimming
data <- sdTrim(data, minRT = 150, sd = 2.5, perCondition = TRUE,
perParticipant = TRUE, omitErrors = FALSE, returnType = "raw")
colnames(data)[1] <- "subject"
head(data)
str(data)
#------------------------------------------------------------------------------
rm(list = ls())
setwd("~/Git/paperData/2015/Mixture Distribution/Model Fit")
# load required libraries & functions
library(dplyr)
source("functions.R")
# get the data (& do trimming & round RTs to nearest integer)
data <- read.csv("data.csv")
data <- subset(data, data$condition == "Memory" & data$errorTrimming == 1 &
data$sequence != "null" & data$sequence == "repeat")
# select essential columns from data file
data <- select(data, subject, ratio, rt, accuracy)
data$condition <- as.character(data$ratio)
colnames(data)[1] <- "participant"
# do the SD trimming
data <- sdTrim(data, minRT = 150, sd = 2.5, perCondition = TRUE,
perParticipant = TRUE, omitErrors = FALSE, returnType = "raw")
colnames(data)[1] <- "subject"
#------------------------------------------------------------------------------
# get the data for QMP
quantiles <- c(.1, .3, .5, .7, .9)
fast <- subset(data, data$ratio == 20)
fast <- prepData(fast)
slow <- subset(data, data$ratio == 0.05)
slow <- prepData(slow)
int <- subset(data, data$ratio == 1)
int <- prepData(int)
data <- list(fast = fast, slow = slow, int = int)
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
### fit the model
## get the starting parameters separately by condition (A, b, drift, s, ter)
slowParms <- getStartParms(data$slow)
fastParms <- getStartParms(data$fast)
intParms <- getStartParms(data$int)
# sort the starting parameters for overall fit
A <- mean(c(slowParms[1], fastParms[1], intParms[1]))
b <- c(fastParms[2], slowParms[2])
driftFast <- fastParms[3]
driftSlow <- slowParms[3]
driftInt <- intParms[3]
s <- mean(c(slowParms[4], fastParms[4], intParms[4]))
ter <- mean(c(slowParms[5], fastParms[5], intParms[5]))
p <- 0.7
# store the parameters
parameters <- c(log(p), log(A), log(b), driftFast, driftSlow, log(s),
log(ter))
# do the fit
fit <- optim(par = parameters, fn = fitFunction, data = data,
list(maxit = 10000, parscale = parameters))
x <- fit$par
x[c(1, 2, 3, 4, 7, 8)] <- exp(x[c(1, 2, 3, 4, 7, 8)])
x <- round(x, 3)
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
### assess the fit
# first, extract the parameters
p <- x[1]
A <- x[2]
bFast <- x[3] + A
bSlow <- x[4] + A
driftFast <- x[5]
driftSlow <- x[6]
s <- x[7]
ter <- x[8]
## get model predictions
n = 50000
# fast condition
fastSim <- simLBA_Mixture(n = n, b = c(bFast, bSlow), a = A,
drift = c(driftFast, driftSlow), s = s, ter = ter,
p = 1)
colnames(fastSim)[3] <- "participant"
fastSim <- sdTrim(fastSim, minRT = 150, sd = 4, perCondition = FALSE,
perParticipant = TRUE, omitErrors = FALSE,
returnType = "raw")
colnames(fastSim)[3] <- "subject"
fastSim <- prepData(fastSim)
# slow condition
slowSim <- simLBA_Mixture(n = n, b = c(bFast, bSlow), a = A,
drift = c(driftFast, driftSlow), s = s, ter = ter,
p = 0)
colnames(slowSim)[3] <- "participant"
slowSim <- sdTrim(slowSim, minRT = 150, sd = 4, perCondition = FALSE,
perParticipant = TRUE, omitErrors = FALSE,
returnType = "raw")
colnames(slowSim)[3] <- "subject"
slowSim <- prepData(slowSim)
# mixture distribution
intSim <- simLBA_Mixture(n = n, b = c(bFast, bSlow), a = A,
drift = c(driftFast, driftSlow), s = s, ter = ter,
p = p)
colnames(intSim)[3] <- "participant"
intSim <- sdTrim(intSim, minRT = 150, sd = 4, perCondition = FALSE,
perParticipant = TRUE, omitErrors = FALSE,
returnType = "raw")
colnames(intSim)[3] <- "subject"
intSim <- prepData(intSim)
## do some plots
# fast
fastHumanCorrectRT <- data$fast$q$correct
fastHumanCorrectCDF <- quantiles * data$fast$p
fastHumanErrorRT <- data$fast$q$error
fastHumanErrorCDF <- quantiles * (1 - data$fast$p)
fastModelCorrectRT <- fastSim$q$correct
fastModelCorrectCDF <- quantiles * fastSim$p
fastModelErrorRT <- fastSim$q$error
fastModelErrorCDF <- quantiles * (1 - fastSim$p)
# intermediate
intHumanCorrectRT <- data$int$q$correct
intHumanCorrectCDF <- quantiles * data$int$p
intHumanErrorRT <- data$int$q$error
intHumanErrorCDF <- quantiles * (1 - data$int$p)
intModelCorrectRT <- intSim$q$correct
intModelCorrectCDF <- quantiles * intSim$p
intModelErrorRT <- intSim$q$error
intModelErrorCDF <- quantiles * (1 - intSim$p)
# slow
slowHumanCorrectRT <- data$slow$q$correct
slowHumanCorrectCDF <- quantiles * data$slow$p
slowHumanErrorRT <- data$slow$q$error
slowHumanErrorCDF <- quantiles * (1 - data$slow$p)
slowModelCorrectRT <- slowSim$q$correct
slowModelCorrectCDF <- quantiles * slowSim$p
slowModelErrorRT <- slowSim$q$error
slowModelErrorCDF <- quantiles * (1 - slowSim$p)
# get min and max RT
minRT <- min(slowHumanCorrectRT, slowHumanErrorRT,
intHumanCorrectRT, intHumanErrorRT,
fastHumanCorrectRT, fastHumanErrorRT,
slowModelCorrectRT, slowModelErrorRT,
intModelCorrectRT, intModelErrorRT,
fastModelCorrectRT, fastModelErrorRT)
maxRT <- max(slowHumanCorrectRT, slowHumanErrorRT,
intHumanCorrectRT, intHumanErrorRT,
fastHumanCorrectRT, fastHumanErrorRT,
slowModelCorrectRT, slowModelErrorRT,
intModelCorrectRT, intModelErrorRT,
fastModelCorrectRT, fastModelErrorRT)
pdf("qmp2RCI_drift + b.pdf", width = 8, height = 4)
par(mfrow = c(1, 3))
# plot slow
plot(slowHumanCorrectRT, slowHumanCorrectCDF, type = "p",
xlim = c(minRT, maxRT), ylim = c(0, 1), main = "0.05", pch = 19,
xlab = "Response Time (ms)", ylab = "Defective CDF")
points(slowHumanErrorRT, slowHumanErrorCDF, type = "p")
lines(slowModelCorrectRT, slowModelCorrectCDF, type = "b", lty = 1, lwd = 1,
pch = 19, cex = 0.2)
lines(slowModelErrorRT, slowModelErrorCDF, type = "b", lty = 2, lwd = 1,
pch = 19, cex = 0.2)
legend("topleft", c("Data (Correct)", "Data (Error)",
"Model (Correct)", "Model (Error)"), cex = 1,
pch = c(19, 1, NA, NA), lty = c(NA, NA, 1, 2),  bty = "n")
# plot intermediate
plot(intHumanCorrectRT, intHumanCorrectCDF, type = "p",
xlim = c(minRT, maxRT), ylim = c(0, 1), main = "1", pch = 19,
xlab = "Response Time (ms)", ylab = "Defective CDF")
points(intHumanErrorRT, intHumanErrorCDF, type = "p")
lines(intModelCorrectRT, intModelCorrectCDF, type = "b", lty = 1, lwd = 1,
pch = 19, cex = 0.2)
lines(intModelErrorRT, intModelErrorCDF, type = "b", lty = 2, lwd = 1,
pch = 19, cex = 0.2)
# plot fast
plot(fastHumanCorrectRT, fastHumanCorrectCDF, type = "p",
xlim = c(minRT, maxRT), ylim = c(0, 1), main = "20", pch = 19,
xlab = "Response Time (ms)", ylab = "Defective CDF")
points(fastHumanErrorRT, fastHumanErrorCDF, type = "p")
lines(fastModelCorrectRT, fastModelCorrectCDF, type = "b", lty = 1, lwd = 1,
pch = 19, cex = 0.2)
lines(fastModelErrorRT, fastModelErrorCDF, type = "b", lty = 2, lwd = 1,
pch = 19, cex = 0.2)
dev.off()
#------------------------------------------------------------------------------
#   p     A       bFast   bSlow     vFast   vSlow   s     ter
round(x, 3)
